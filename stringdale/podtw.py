# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/016_partial_order_dynamic_time_warping.ipynb.

# %% auto 0
__all__ = ['logger', 'int_to_excel_col', 'LabelToVar', 'word_overlap', 'regex', 'Condition', 'ExpectedTraceStep', 'ExpectedTrace',
           'Trace', 'parse_expected_trace_step', 'parse_expected_trace', 'compute_trace_distance', 'compute_distances',
           'get_possible_mappings', 'get_best_mapping', 'align_traces']

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 3
import os
import json
from frozendict import frozendict
from collections import defaultdict

from pydantic import BaseModel, ConfigDict
from typing import List, Any, Dict, Callable,Set, Optional

import numpy as np
import itertools as it
import re
import asyncio

from constraint import Problem,FunctionConstraint
from bidict import bidict

import logging 
from .core import checkLogs
from .mappings import access_object, parse_edge_descriptor


# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 4
logger = logging.getLogger(__name__)

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 6
def int_to_excel_col(n):
    if n < 0:
        raise ValueError("Number must be non-negative")
    
    result = ""
    n += 1  # Adjust because Excel columns start at 1, not 0
    
    while n > 0:
        n -= 1  # Adjust for 0-based indexing
        result = chr(n % 26 + ord('A')).lower() + result
        n //= 26
        
    return result

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 8
class LabelToVar():
    def __init__(self):
        self.label_to_var = bidict()
        self.label_to_index = bidict()

    def add_label(self,label:str,idx:int):
        self.label_to_var[label] = int_to_excel_col(idx)
        self.label_to_index[label] = idx

    def get_label(self,col:str) -> str:
        return self.label_to_var.inverse[col]

    def get_index(self,label:str) -> int:
        return self.label_to_index[label]

    def get_col(self,label:str) -> int:
        return self.label_to_var[label]


# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 11
async def word_overlap(result: str, expected: str,**kwargs) -> float:
    """
    Calculate the distance between result and expected strings based on word overlap.
    Returns a value between 0 and 1, where:
    - 0 means perfect match (all words from result are in expected)
    - 1 means no overlap (no words from result are in expected)
    
    Args:
        result (str): The string to check words from
        expected (str): The string to check words against
        
    Returns:
        float: Distance metric between 0 and 1
    """
    if not isinstance(result,str) or not isinstance(expected,str):
        return np.inf
    # Convert both strings to lowercase and split into words
    result_words = set(result.lower().split())
    expected_words = set(expected.lower().split())
    
    # If result is empty, return 1.0 (maximum distance)
    if not result_words:
        return 1.0
    
    # Calculate overlap
    overlap = len(result_words.intersection(expected_words))
    total = len(result_words)
    
    # Calculate distance (1 - percentage)
    distance = 1.0 - (overlap / total)
    
    return distance

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 14
def regex(out: str, expected: str,**kwargs) -> float:
    """
    Compare a string against a regex pattern.
    Returns 0 if the regex matches, 1 if it doesn't.
    
    Args:
        out (str): The string to check
        expected (str): The regex pattern to match against
        
    Returns:
        float: 0 if match, 1 if no match
    """
    if not isinstance(out,str) or not isinstance(expected,str):
        return np.inf
    try:
        if re.search(expected, out,flags=re.IGNORECASE) is not None:
            return 0.0
        return 1.0
    except Exception:
        return 1.0


# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 21
from typing import Dict, Any,Optional, Union, List
from pathlib import Path
from pprint import pprint
import yaml

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 22
class Condition(BaseModel):
    accessor: tuple[str, ...]
    value: Any
    comparison: Optional[str] = None
    kwargs: Dict[str,Any] = {}

class ExpectedTraceStep(BaseModel):
    name: str
    label: Union[str,int]
    conditions: List[Condition]
    before: Optional[List[Union[str,int]]] = None
    after: Optional[List[Union[str,int]]] = None

class ExpectedTrace(BaseModel):
    input: List[Any]
    expected: List[ExpectedTraceStep]

class Trace(BaseModel):
    model_config = ConfigDict(extra='allow')
    name: str
    output: Any

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 23
def parse_expected_trace_step(yaml_obj: Dict[str,Any],idx:int,labels:List[str]) -> ExpectedTraceStep:
    if len(yaml_obj.keys()) != 1:
        raise SyntaxError(f"Expected a single key in trace step {idx}, got {yaml_obj.keys()}")
    
    name = list(yaml_obj.keys())[0]
    value = yaml_obj[name]
    label = value.pop("$label",None)
    if label is None:
        label = str(idx)

    before = value.pop("$before",list())
    if isinstance(before,str):
        before = [before]
    after = value.pop("$after",list())
    if isinstance(after,str):
        after = [after]
    parallel = value.pop("$parallel",False)

    if parallel and idx == 0:
        raise ValueError(f"Expected trace step {idx} is has $parallel: true, but is the first step")

    if not parallel and len(after) == 0 and idx > 0:
        after.append(labels[-1])
    
    conditions = []
    for accessor,params in value.items():
        if isinstance(params,str):
            params = {"value":params}
        try:
            accessor = parse_edge_descriptor(accessor,start='accessor')
        except Exception as e:
            raise SyntaxError(f"Error parsing accessor {accessor} for step {idx}. Make sure it is formatted correctly") from e
        condition_data ={
            'accessor':accessor,
            **params
        }
        try:
            conditions.append(Condition.model_validate(condition_data))
        except Exception as e:
            raise SyntaxError(f"When parsing condition {value} for step {idx}") from e
    
    return ExpectedTraceStep(name=name,label=label,conditions=conditions,before=before,after=after)
        
    

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 28
def parse_expected_trace(yaml_str: str) -> ExpectedTrace:
    if isinstance(yaml_str,Path):
        yaml_string = yaml_str.read_text()
    else:
        yaml_string = yaml_str
    
    try:
        yaml_obj = yaml.safe_load(yaml_string)
    except Exception as e:
        raise SyntaxError(f"Error parsing yaml:\n{yaml_string}\n{e}")

    if list(yaml_obj.keys()) != ["input","expected"]:
        raise SyntaxError(f"Expected keys in main scope are 'input' and 'expected', got {yaml_obj.keys()}")

    input = yaml_obj["input"]
    if not isinstance(input,list):
        input = [input]
    expected = yaml_obj["expected"]

    parsed_steps = []
    labels = []
    for i,expected_step in enumerate(expected):
        try:
            step = parse_expected_trace_step(expected_step,i,labels)
            parsed_steps.append(step)
            labels.append(step.label)
        except Exception as e:
            raise SyntaxError(f"Error parsing expected trace step:\n{expected_step}") from e
    return ExpectedTrace(input=input,expected=parsed_steps)



# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 31
from .core import maybe_await

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 32
async def compute_trace_distance(trace,expected,comparisons,default_comparison):

    logger.debug(f"Computing distance for trace {trace} and expected {expected}")
    if not re.search(expected.name, trace.name):
        return None,[]
    
    # check if all accessors are in the trace
    for condition in expected.conditions:
        try: 
            sub_object = access_object(trace.output,condition.accessor)
        except Exception as e:
            return None, []

    distance = 0
    debug_info = []
    # TODO current different conditions are computed sequentially, but we should compute them in parallel
    for condition in expected.conditions:
        condition_func = comparisons.get(condition.comparison, default_comparison)
        output_sub_value = access_object(trace.output,condition.accessor)
        try:
            condition_distance = await maybe_await(condition_func,args=[output_sub_value, condition.value],kwargs=condition.kwargs)
        except Exception as e:
            logger.error(f"Error computing distance for:\n"
                    f"trace {trace.name}\n"
                    f"condition function {condition_func}\n"
                    f"with accessor {condition.accessor}\n"
                    f"accessed value {repr(sub_object)}\n"
                    f"expected value {repr(condition.value)}\n"
                    f"with error: {e}")
            condition_distance = np.inf
        distance += condition_distance
        debug_info.append({
            "comparison": condition_func.__qualname__,
            "kwargs": condition.kwargs,
            "expected": condition.value,
            "actual": output_sub_value,
            "distance": condition_distance,
            "accessor": '.'.join(condition.accessor),
        })
    
    return distance,debug_info


# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 33
async def compute_distances(
    traces_outputs:List[Any],
    expected_trace:ExpectedTrace,
    comparisons:Dict[str,Callable],
    default_comparison:Callable,
    ):
    """
    Compute the distance matrix between the traces and the expected traces.

    Args:
        traces_outputs: List[Any], the outputs of the traces
        expected_traces: ExpectedTrace, the expected traces
        comparisons: Dict[str,Callable], the comparisons to use for the distance matrix
        default_comparison: Callable, the default comparison to use for the distance matrix
        log_errors: bool, if True, distance computations that raised an exception will be logged as errors, with the distance set to np.inf
    """
    expected_steps = expected_trace.expected
    distances = dict()
    for expected_step in expected_trace.expected:
        distances[expected_step.label] = dict()
    debug_info = defaultdict(dict)
    
    a_iter = list(it.product(enumerate(traces_outputs), enumerate(expected_steps)))
    tasks = [
        compute_trace_distance(trace,expected,comparisons,default_comparison)
        for (i, trace), (j, expected) in a_iter
    ]
    distance_list = await asyncio.gather(*tasks)
    
    for ((i, trace), (j, expected)), (d,debug) in zip(a_iter, distance_list):
        if not d == None:
            if not d == np.inf:
                distances[expected.label][i] = d
            debug_info[expected.label][i]={
                'comparisons':debug,
                'distance':d,
                'expected_idx':j,
                'actual_idx':i,
                'actual_name':trace.name,
                'expected_name':expected.name,
                'expected_label':expected.label,
            }

    return dict(distances),dict(debug_info)
    

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 40
def get_possible_mappings(dist,expected_traces:ExpectedTrace,label_to_var:LabelToVar):
    """
    Gets possible mappings between expected traces and actual traces.
    By building a constraint satisfaction problem and solving it.
    """
    p = Problem()
    logger.debug(
        f"Adding variables for {expected_traces.expected}\n"
        f"dist: {dist}"
        f"label_to_var: {label_to_var}"
        )

    for col_idx,expected_step in enumerate(expected_traces.expected):
        viable_trace_row_nums = list(dist[expected_step.label].keys())
        if not viable_trace_row_nums:
            logger.warning(f"No viable trace row nums for expected trace {expected_step.label}")
            return None
        var_name = label_to_var.get_col(expected_step.label)
        p.addVariable(var_name,viable_trace_row_nums)
        logger.debug(f"Adding variable {var_name} with domain {viable_trace_row_nums}")

        for before_label in expected_step.before:
            before_var_name = label_to_var.get_col(before_label)
            logger.debug(f"Adding constraint {before_var_name} < {var_name}")
            p.addConstraint(f"{var_name} < {before_var_name}")

        for after_label in expected_step.after:
            after_var_name = label_to_var.get_col(after_label)
            logger.debug(f"Adding constraint {var_name} < {after_var_name}")
            p.addConstraint(f"{after_var_name} < {var_name}")

    # these solutions use colnames    
    solutions = p.getSolutions()
    # invert the colnames back to labels
    labeled_solutions = set(frozendict({label_to_var.get_label(k):v for k,v in sol.items()}) for sol in solutions)
    return labeled_solutions

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 46
def get_best_mapping(dist_matrix,possible_mappings,label_to_var):
    """
    dist_matrix: np.ndarray
    possible_mappings: list of tuples
    label_to_var: dict
    """
    
    score_per_solution = {}
    for sol in possible_mappings:
        sum_dist = 0
        for expected_label,trace_idx in sol.items():
            sum_dist += dist_matrix[expected_label][trace_idx]
        score_per_solution[sol] = sum_dist

    best_solution =  min(score_per_solution,key=score_per_solution.get)
    best_solution_score = score_per_solution[best_solution]
    return best_solution,best_solution_score

# %% ../nbs/016_partial_order_dynamic_time_warping.ipynb 48
async def align_traces(traces_outputs,expected_trace,comparisons,default_comparison):
    """
    Compute the distance matrix between the traces and the expected traces.
    """
    label_to_var = LabelToVar()
    for idx,expected_step in enumerate(expected_trace.expected):
        label_to_var.add_label(expected_step.label,idx)

    dist,debug_info = await compute_distances(traces_outputs,expected_trace,comparisons,default_comparison)
    possible_mappings = get_possible_mappings(dist,expected_trace,label_to_var)
    if not possible_mappings:
        logger.warning("No possible mappings found")
        return None, np.inf, debug_info
    best_mapping,best_score = get_best_mapping(dist,possible_mappings,label_to_var)
    return best_mapping, best_score, debug_info


