{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from stringdale.core import get_git_root, load_env, checkLogs, json_render\n",
    "\n",
    "load_env()\n",
    "\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Union,Literal\n",
    "\n",
    "from stringdale.diagrams import (\n",
    "    Define,Scope,\n",
    "    V,E,\n",
    "    draw_diagram\n",
    ")\n",
    "from stringdale.core import has_missing\n",
    "from stringdale.chat import Chat\n",
    "from stringdale.std import Condition as C\n",
    "from stringdale.tools import google_search, wikipedia_search,run_python_code\n",
    "from stringdale.chat import speech_to_text,image_to_text\n",
    "import logging\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlmodel import SQLModel, Session, select, Field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracing ideas:\n",
    "* log all trace objects to axiom\n",
    "* or langfuse (but they get expensive quickly, so maybe just log llm and rag calls and use them to define metrics)\n",
    "\n",
    "* add the func called during a node to the trace object\n",
    "* show examples on how to trace conditionally based on node names or whether there is a real function call\n",
    "* show how to add a metadata method to a function object and add it to a metadata field in the trace object\n",
    "* build the debug app that takes a run id and plots it\n",
    "  * probably a react app that uses shadcn and is hosted on modal or locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO from here\n",
    "# supabase with pgvector RAG agents and RAG upload agents\n",
    "# collect userdata with SQL with explicit State management\n",
    "# monitor agent\n",
    "# supervisor agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rag summary, summarize each chunk if it is too long \n",
    "# and then use the summaries to answer the question\n",
    "\n",
    "# Superviser agent, deligate to sub agents, either QA, analytical or common sense question\n",
    "\n",
    "# reranking agent, rerank the results of the rag agent based on a smaller model, see how pinecone does it\n",
    "# and then use the reranked results to answer the question\n",
    "\n",
    "# chunked header, ask an llm to make a header and then embedd both of them.\n",
    "\n",
    "# write questions that the fragment can answer with LLM and embedd each question with the document fragment\n",
    "\n",
    "# contextual compression, ask an llm to extract the relevant information from the document based on the task\n",
    "\n",
    "# RAG with namespace that has a topics list, choose relevant topics and then rag them.\n",
    "\n",
    "# rag about splitting documents, have a context size around a splitted page\n",
    "    # put the before and after of the page in the metadata\n",
    "\n",
    "# rag with explanation about why each document is relevant\n",
    "\n",
    "# encoding source url for documnet in the metadata and use it to answer questions about the document as the sources.s\n",
    "\n",
    "# corrective RAG, if relevance of documents is not good enough, answer only based on a google search or combine \n",
    "# the google search with the retrived documents. List sources in the answer.\n",
    "    # for google search, use a 2 phase search, use the sources fo the first answer to rewrite the query into a better one\n",
    "\n",
    "# fusion retrieval - doucment store and keyword search, we take a weighted combination of the results of the two searches to rank the documents and then use them for generating the answer\n",
    "\n",
    "# graph RAG, we build a graph that links relevant chunks (see the graph rag nb)\n",
    "# than when querying, we take the best chunk, and gradually add more chunks to the context until we have a good answer\n",
    "# adding is based on  a dikjstra like algorithm that uses edge weights to add the most relevant additional chunk each time.\n",
    "\n",
    "\n",
    "# hierarchical RAG, we encode whole documents and their chunks into different vector dbs.\n",
    "# we than query the relevant chunks, and then look for the most relevant chunk out of those.\n",
    "# requires a filter on the metadata.\n",
    "\n",
    "# hypothetical rag, generate a hypothetical document that would answer the question and use it to query the vector db\n",
    "\n",
    "# proposition chunking, we generate self contained propositions from text with llm. \n",
    "# We then QA that the proposition is accurate and clear with an LLM.\n",
    "    # proposition generation and Grades for accuracy and clarity completeness etc are computed via structured output\n",
    "# we then use this propositions as the basis of a vector score for rag.\n",
    "\n",
    "# more examples of query transformations\n",
    " # rewrite query\n",
    " # generalize query \n",
    " # break apart the query into subqueries and then query each one from a vecdb\n",
    "\n",
    "\n",
    "# dynamic strategy agent, decompose the task into sub tasks, and then deligate the subtask into a REACT agent\n",
    "# that has a vecdb tool to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(*x):\n",
    "    return sum(x)\n",
    "\n",
    "f(1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_args = [1,2,3,4]\n",
    "f(*list_of_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO clean up the examples and make the agent tutorial work without mocks\n",
    "# TODO maybe make the agent tutorial work with mocks of vecdb or something\n",
    "\n",
    "\n",
    "# than we get the user_id from start, we save it and we query the db for the user\n",
    "# if we get in the break point, the timeout string, we go to save data and then to end\n",
    "# if we there are no missing we go to save data.\n",
    "\n",
    "#TODO check for JSON type in sql\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO show example of dynamically changing the choices of a Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other agents to do\n",
    "\n",
    "# asking questions from user to fill out form\n",
    "# asking questions from user to fill out form continue from DB\n",
    "# routing to the right agent\n",
    "\n",
    "# saving documents and then using them, 2 different diagrams\n",
    "# programmer\n",
    "\n",
    "# diamant rag examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
