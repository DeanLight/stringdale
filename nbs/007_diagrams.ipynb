{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from stringdale.core import  checkLogs\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from copy import deepcopy,copy\n",
    "import itertools\n",
    "import logging\n",
    "import asyncio\n",
    "\n",
    "from collections import defaultdict,OrderedDict\n",
    "from contextlib import ExitStack\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from typing import Optional,Union,List,Dict,Any,Literal,Callable\n",
    "from fastcore.basics import patch\n",
    "import logging\n",
    "\n",
    "from stringdale.core import wrap_exception\n",
    "from stringdale.schema import (\n",
    "    DiagramSchema,draw_diagram,BaseModelExtra,DiagramType\n",
    "    ,_is_attr_method,get_state_key,set_state_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Diagram():\n",
    "    \"\"\"\n",
    "    An instance of a stringdale diagram. Instantiated by calling the Schema()\n",
    "\n",
    "    Has the following public attributes:\n",
    "    output - the output of the last run\n",
    "    finished - whether the diagram has reached the End node\n",
    "    state - the current state of the diagram\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,graph,funcs,type,state:BaseModel,schema:DiagramSchema,anon=False,root=None):\n",
    "        self.graph = graph\n",
    "        self.funcs = funcs\n",
    "        self.type = type\n",
    "        self.state = state\n",
    "        self.schema = schema\n",
    "        self.anon = anon\n",
    "        self.root = root\n",
    "        self.schema_nodes = list(schema.graph.nodes)\n",
    "        \n",
    "        for node,func in self.funcs.items():\n",
    "            if isinstance(func,DiagramSchema):\n",
    "                raise ValueError(f\"DiagramSchema nodes are not allowed in a Diagram, they must be instantiated before being added to a Diagram\")\n",
    "\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = None\n",
    "        self.finished=None\n",
    "        self.output = None\n",
    "        self.run_uid = str(uuid.uuid4())\n",
    "\n",
    "        for node,func in self.funcs.items():\n",
    "            if _is_attr_method(node_func,'reset'):\n",
    "                node_func.reset()\n",
    "    \n",
    "    @property\n",
    "    def attrs_to_serialize(self):\n",
    "        return ['output','finished','next_node','run_uid']\n",
    "\n",
    "    def __getstate__(self):\n",
    "        \"\"\"Dump the state of the diagram and all its nodes into a json serializable dictionary\n",
    "        \"\"\"\n",
    "        state_dict = dict()\n",
    "        if self.state is not None:\n",
    "            state_dict['state'] = self.state.model_dump()\n",
    "        else:\n",
    "            state_dict['state'] = None\n",
    "\n",
    "        for attr in self.attrs_to_serialize:\n",
    "            if hasattr(self,attr):\n",
    "                state_dict[attr] = getattr(self,attr)\n",
    "\n",
    "        if not self.anon:\n",
    "            state_dict['node_state'] = dict()\n",
    "            for node,func in self.funcs.items():\n",
    "                if _is_attr_method(func,'__getstate__'):\n",
    "                    state_dict['node_state'][node] = deepcopy(func.__getstate__())\n",
    "        return state_dict\n",
    "\n",
    "    def __setstate__(self,state_dict):\n",
    "        \"\"\"Load the state of the diagram and all its nodes from a json serializable dictionary\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        if state_dict.get('state',None) is not None:\n",
    "            self.state = self.state_class(**state_dict['state'])\n",
    "\n",
    "        for attr in self.attrs_to_serialize:\n",
    "            setattr(self,attr,state_dict[attr])\n",
    "\n",
    "        if self.anon:\n",
    "            return\n",
    "        \n",
    "        for node,state_obj in state_dict['node_state'].items():\n",
    "            if node in self.factored_graph.nodes:\n",
    "                node_func = self.factored_graph.nodes[node].get('func',None)\n",
    "                if _is_attr_method(node_func,'__setstate__'):\n",
    "                    node_func_copy = deepcopy(node_func)\n",
    "                    logger.debug(f\"Creating copy of {node_func}, {node_func_copy} for loading state\")\n",
    "                    node_func_copy.__setstate__(deepcopy(state_obj))\n",
    "                    self.factored_graph.nodes[node]['func'] = node_func_copy\n",
    "                else:\n",
    "                    raise ValueError(f\"Node '{node}' state {state_obj} was saved but has no __setstate__ method is found for {node_func}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO from here, make simple diagrams decision and flow, with state and without,\n",
    "# and compound diagrams\n",
    "# and nested subdiagrams\n",
    "\n",
    "# TODO, put diagram basics in the schema call it diagram_base\n",
    "\n",
    "# this nb will be called execution and be put after the declerative definition nb\n",
    "# and excution will patch the diagram from the schema logic\n",
    "\n",
    "# in init we will import all of these modules and therefore patch the classes\n",
    "# that way we can use the declerative syntax to test the execution logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing state and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_root(self:Diagram):\n",
    "    if self.anon:\n",
    "        return self.root\n",
    "    else:\n",
    "        return self\n",
    "\n",
    "@patch\n",
    "def __getitem__(self:Diagram,key):\n",
    "    return self.get_root().funcs.get(key,None)  \n",
    "\n",
    "@patch\n",
    "def __setitem__(self:Diagram,key,value):\n",
    "    self.get_root().funcs[key] = value\n",
    "\n",
    "\n",
    "@patch\n",
    "def get_state(self:Diagram,key):\n",
    "    state = self.get_root().state\n",
    "    return get_state_key(state,key)\n",
    "\n",
    "@patch\n",
    "def set_state(self:Diagram,key,value):\n",
    "    state = self.get_root().state\n",
    "    set_state_key(state,key,value)\n",
    "\n",
    "\n",
    "def simplify_output(input_):\n",
    "    if isinstance(input_,dict) and len(input_) ==1 and 0 in input_:\n",
    "        output = input_[0]\n",
    "    else:\n",
    "        output = input_ \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def _set_node_output(self:Diagram, node, output):\n",
    "    # for each write state, get the output at the port position and set it to the state at based on the key\n",
    "    graph = self.graph\n",
    "    for key,mapping in graph.nodes[node].get('write_state',{}).items():      \n",
    "        object_to_write = simplify_output(map_object(output,mapping))\n",
    "        logger.debug(f\"Setting state '{key}' based on output {output}\\n\"\n",
    "                    f\"after mapping it to {object_to_write}\\n\"\n",
    "                    f\"with mapping {mapping}\")\n",
    "        self.set_state(key,object_to_write)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@patch\n",
    "def _get_state_input_keys(self:Diagram,node):\n",
    "    return list(self.graph.nodes[node].get('read_state',{}).keys())\n",
    "@patch\n",
    "def _get_state_input(self:Diagram,node):\n",
    "    keys = self._get_state_input_keys(node)\n",
    "    return {('state',key):simplify_output(self.get_state(key)) for key in keys}\n",
    "\n",
    "@patch\n",
    "def compute_node_input(self:Diagram,node,previous_outputs,state,raw_input=False,partial=False):\n",
    "    \"\"\"Prepare the input for the next node execution\"\"\"\n",
    "    \n",
    "    graph = self.factored_graph\n",
    "    logger.debug(f\"diagram {self.name} preparing input for node '{node}' based on previous outputs {previous_outputs}\")\n",
    "\n",
    "    port_mappings = graph.nodes[node]['mapping']\n",
    "\n",
    "    state_objects = self._get_state_input(node)\n",
    "\n",
    "    if raw_input:\n",
    "        object_to_map = state_objects\n",
    "    else:\n",
    "        object_to_map = previous_outputs | state_objects\n",
    "\n",
    "    func_input = multi_map(object_to_map,port_mappings)\n",
    "\n",
    "    if raw_input:\n",
    "        if isinstance(previous_outputs,dict):\n",
    "            func_input = previous_outputs|func_input\n",
    "        else:\n",
    "            func_input = {0:simplify_output(previous_outputs)}|func_input\n",
    "\n",
    "    logger.debug(f\"diagram {self.name} for node '{node}' input prepared:{func_input}\")\n",
    "\n",
    "    return func_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "\n",
    "def _before_node(self:Diagram,node,input_):\n",
    "    # if we got a validator, validate the input\n",
    "    self._validate_node_input(node,input_)\n",
    "    \n",
    "    return self[node]\n",
    "\n",
    "@patch\n",
    "def _after_node(self:Diagram,node,output):\n",
    "    self._validate_node_output(node,output)\n",
    "    # set the output to the outbound state\n",
    "    self._set_node_output(node,output)\n",
    "    return \n",
    "\n",
    "@patch\n",
    "def _validate_node_input(self:Diagram,node,func_input):\n",
    "    # get the input validator\n",
    "    # if validator is basemodel, and there is only a singel arg, validate it\n",
    "    # if validator is basemodel, and there are only kwargs, validate them as a dict\n",
    "    # if validator is basemodel, and there are args and kwargs, log a warning\n",
    "\n",
    "    # if validator is callable, run it on input as args and kwargs\n",
    "    return \n",
    "\n",
    "@patch\n",
    "def _validate_node_output(self:Diagram,node,output):\n",
    "    # get the output validator\n",
    "    # if validator is basemodel validate it against it\n",
    "    # if validator is callable, run it on output as a single arg\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, computed_field\n",
    "from pprint import pprint\n",
    "from typing import Dict,Any,Literal,Union,List\n",
    "\n",
    "from pprint import pformat\n",
    "from textwrap import indent\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "import reprlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TruncatedPrettyPrinter(PrettyPrinter):\n",
    "    def __init__(self, *args, str_length=100, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.str_length = str_length\n",
    "\n",
    "    def _format(self, obj, stream, indent, allowance, context, level):\n",
    "        if isinstance(obj, str):\n",
    "            if len(obj) > self.str_length:\n",
    "                # Truncate string and add ...\n",
    "                stream.write(repr(obj[:self.str_length] + '...'))\n",
    "                return\n",
    "        super()._format(obj, stream, indent, allowance, context, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Trace(BaseModel):\n",
    "    model_config = {\"arbitrary_types_allowed\": True}\n",
    "    run_uid: str\n",
    "    node_uid: str\n",
    "    node_name: List[str]\n",
    "    input_idx: List[Union[int,None]] = [None]\n",
    "    node_func: Optional[Any] = None\n",
    "    input_state_keys: Optional[set[str]] = None\n",
    "    input_: Any\n",
    "    output: Optional[Any] = None\n",
    "    run_type: DiagramType\n",
    "    start_time: Optional[datetime] = None\n",
    "    end_time: Optional[datetime] = None\n",
    "\n",
    "    @computed_field\n",
    "    def duration(self) -> Optional[datetime]:\n",
    "        \"\"\"Return the duration of the node execution in seconds\"\"\"\n",
    "        if self.start_time is None or self.end_time is None:\n",
    "            return None\n",
    "        return (self.end_time - self.start_time).total_seconds()\n",
    "\n",
    "    def nest(self,name,idx):\n",
    "        self.node_name.insert(0,name)\n",
    "        self.input_idx.insert(0,idx)\n",
    "\n",
    "    def pretty_name(self):\n",
    "        name_parts = []\n",
    "        for name,idx in zip(self.node_name,self.input_idx):\n",
    "            if idx is None:\n",
    "                name_parts.append(name)\n",
    "            else:\n",
    "                name_parts.append(f\"{name}[{idx}]\")\n",
    "        return '.'.join(name_parts)\n",
    "\n",
    "    def pformat(self,show_input=True,show_output=True,show_input_state=True,depth=None,indent=2,width=80,str_max_length=None):\n",
    "\n",
    "        data = {}\n",
    "        \n",
    "        if show_input_state == False and isinstance(printable_input,dict):\n",
    "            printable_input = {k:v for k,v in self.input_.items() if k not in self.input_state_keys}\n",
    "        else:\n",
    "            printable_input = self.input_\n",
    "    \n",
    "        if show_input:\n",
    "            data['input'] = printable_input\n",
    "        if show_output:\n",
    "            data['output'] = self.output\n",
    "\n",
    "        if str_max_length is not None:\n",
    "            pp = TruncatedPrettyPrinter(str_length=str_max_length,indent=indent,width=width,depth=depth)\n",
    "        else:\n",
    "            pp = PrettyPrinter(indent=indent,width=width,depth=depth)\n",
    "        return pp.pformat(data)\n",
    "\n",
    "    def write(self,string,file=None):\n",
    "        if file is None:\n",
    "            fptr = sys.stdout\n",
    "        else:\n",
    "            fptr = open(file,'a')\n",
    "        fptr.write(string+'\\n')\n",
    "        if file is not None:\n",
    "            fptr.close()\n",
    "\n",
    "    def pprint(self,\n",
    "        show_input=True,\n",
    "        show_output=True,\n",
    "        show_input_state=True,\n",
    "        depth=None,\n",
    "        indent=2,\n",
    "        width=80,\n",
    "        str_max_length=None,\n",
    "        skip_passthrough=False,\n",
    "        file=None):\n",
    "        \"\"\"\n",
    "        Print the trace in a pretty format\n",
    "        Args:\n",
    "            show_input (bool, default=True): Whether to show the input data\n",
    "            show_output (bool, default=True): Whether to show the output data \n",
    "            show_input_state (bool, default=True): Whether to show input state data\n",
    "            depth (int, optional): Maximum depth to print nested structures\n",
    "            indent (int, default=2): Number of spaces for each indentation level\n",
    "            width (int, default=80): Maximum line width for pretty printing\n",
    "            str_max_length (int, optional): Maximum length for string values before truncating\n",
    "            skip_passthrough (bool, default=False): Whether to skip printing passthrough nodes (nodes with no function)\n",
    "            file (str, optional): File to write the output to. Defaults to None. which prints to stdout\n",
    "        \"\"\"\n",
    "        if skip_passthrough and self.node_func is None:\n",
    "            return\n",
    "        self.write(f'Node {self.pretty_name()}:',file=file)\n",
    "        self.write(self.pformat(show_input,show_output,show_input_state,depth,indent,width,str_max_length),file=file)\n",
    "        self.write('='*width,file=file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def prep_trace(self:Diagram,node,input_,output,type=DiagramType.decision,idx=None,start_time=None,end_time=None):\n",
    "    input_state_keys = self.graph.nodes[node].get('read_state',{}).keys()\n",
    "    return Trace(\n",
    "        run_uid = self.run_uid,\n",
    "        node_uid = str(uuid.uuid4()),\n",
    "        node_name = [node],\n",
    "        input_idx = [idx],\n",
    "        node_func = self[node],\n",
    "        input_state_keys = input_state_keys,\n",
    "        input_ = input_,\n",
    "        output = output,\n",
    "        run_type = type,\n",
    "        start_time = start_time,\n",
    "        end_time = end_time\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "async def run_node(self:Diagram,node,input_,idx=None):\n",
    "\n",
    "    graph = self.graph\n",
    "    \n",
    "    func = self._before_node(node,input_)\n",
    "    \n",
    "    logger.debug(f\"Running node '{node}[{idx}]' with input {input_} and state {self.state}\")\n",
    "    if func is None:\n",
    "        output = simplify_output(input_)\n",
    "    else:\n",
    "        args,kwargs = object_to_args_kwargs(input_)\n",
    "        try:\n",
    "            # run the node\n",
    "            output = await maybe_await(func,args,kwargs)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"When running node '{node}[{idx}]':\\n\"\n",
    "                f\"Function {func}(args={args},kwargs={kwargs})\\nreturned\\nError '{e}'\\n\") from e\n",
    "\n",
    "    logger.debug(f\"{node}({input_})={output}\")\n",
    "    self._after_node(node,output) \n",
    "    return input_,output\n",
    "\n",
    "\n",
    "@patch\n",
    "async def run_subdiagram_iter(self:Diagram,node,input_,subdiagram,idx=None):\n",
    "    \"\"\"\n",
    "    Run a subdiagram as a node\n",
    "    yields traces from the subdiagram\n",
    "    returns the output of the subdiagram and the subdiagram itself\n",
    "    \"\"\"\n",
    "    graph = self.graph\n",
    "\n",
    "    _ = self._before_node(node,input_)\n",
    "\n",
    "    func = subdiagram\n",
    "\n",
    "    # run the sub diagram via its run method as an iterator,\n",
    "    # yield traces from the sub diagram\n",
    "    if self.derive_state:\n",
    "        state = self.state\n",
    "    else:\n",
    "        state = None\n",
    "    async for trace in subdiagram.arun(input_,state = state,progress_bars=self.progress_bars):\n",
    "        # append the name of the node to the last node and nodes with a '.' delimiter\n",
    "        if not self.trace_nested:\n",
    "            # if we dont want nested trace print yielding them.\n",
    "            continue\n",
    "        if not subdiagram.anon:\n",
    "            trace.nest(node,idx)\n",
    "        yield trace\n",
    "\n",
    "    # after the subdiagram is done, set the output to the outbound state\n",
    "    self._after_node(node,subdiagram.output)\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Decision Diagrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "decision_logger = logging.getLogger(f'{__name__}.decision')\n",
    "\n",
    "@patch\n",
    "async def arun_decision(self:Diagram,input_,state,**kwargs):\n",
    "\n",
    "    logger.debug(f\"Running decision diagram {self.name} with input {input_}\")\n",
    "    if self.finished in [True,None]:\n",
    "        self.finished = False\n",
    "        current_node = self.start_node\n",
    "    else:\n",
    "        current_node = self.next_node\n",
    "\n",
    "    graph = self.graph\n",
    "    # no need to map ports on iteration\n",
    "    raw_input = True\n",
    "\n",
    "    while True:\n",
    "        func = self[current_node]\n",
    "        is_sub_diagram = isinstance(func,Diagram)\n",
    "        is_anon_sub_diagram = is_sub_diagram and func.anon\n",
    "\n",
    "        input_ = self.compute_node_input(current_node,input_,self.state,raw_input,partial=True)\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        if is_sub_diagram:\n",
    "            subdiagram = func\n",
    "            async for trace in self.run_subdiagram_iter(current_node,input_,subdiagram,**kwargs):\n",
    "                yield trace\n",
    "            output = subdiagram.output\n",
    "        else:\n",
    "            _,output = await self.run_node(current_node,input_,**kwargs)\n",
    "        # TODO the delta time should also work for sub diagrams with breakpoints, for the entire duration until they finished, excluding waiting time to continue.\n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        sub_dir_break = is_sub_diagram and subdiagram.finished == False\n",
    "\n",
    "        raw_input = False\n",
    "        if not (is_anon_sub_diagram or sub_dir_break):\n",
    "            yield self.prep_trace(current_node,input_=input_,output=output,type=DiagramType.decision)\n",
    "\n",
    "        if sub_dir_break:\n",
    "            next_node = current_node\n",
    "            logger.debug(f\"Sub diagram {current_node} is not finished, will continue from it when run again\")\n",
    "        else:\n",
    "            next_node = self.choose_next_node(current_node,output)\n",
    "            logger.debug(f\"Choosing next node after {current_node} with output {output}: {next_node}\")\n",
    "        \n",
    "        is_end = next_node is None\n",
    "\n",
    "        is_break = sub_dir_break or (not is_end and graph.nodes[next_node].get('is_break',False))\n",
    "\n",
    "        # if we are at the end or a breakpoint,\n",
    "        # prep for the next run and exit\n",
    "        if is_end:\n",
    "            self.finished = True\n",
    "        if is_end or is_break:\n",
    "            # set the output as the output of the last node we run\n",
    "            saved_output = output\n",
    "            \n",
    "            self.output = simplify_output(output)\n",
    "            # set the next node to run\n",
    "            self.next_node = next_node\n",
    "            return \n",
    "        \n",
    "        input_ = {current_node:output}\n",
    "        current_node = next_node\n",
    "\n",
    "    logger.debug(f\"Decision diagram {self.name} finished with output {self.output}\")\n",
    "    # should never get here\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def choose_next_node(self:Diagram,node,output):\n",
    "    \"\"\"\n",
    "    Based on the output of the last node, choose the next node\n",
    "    returns the next node to run, or None if we are at the end\n",
    "    \"\"\"\n",
    "\n",
    "    graph = self.graph\n",
    "    if node ==self.end_node:\n",
    "        return None\n",
    "\n",
    "    # get a dict with each condition and its target node \n",
    "    # and get the default target node\n",
    "    # based on the outgoing edges from the node\n",
    "\n",
    "    out_going_edges = {target:data for source,target,data in graph.out_edges(node,data=True)}\n",
    "    condition_per_target = {}\n",
    "    for target,data in out_going_edges.items():\n",
    "        if 'condition' in data:\n",
    "            condition_per_target[target] = data['condition']\n",
    "        else:\n",
    "            default_target = target\n",
    "    logger.debug(f\"Condition per target for node '{node}': {condition_per_target}\")\n",
    "    # run the condition functions of each target node on the output\n",
    "    condition_results = {}\n",
    "    for target,condition_func in condition_per_target.items():\n",
    "        try:\n",
    "            condition_result = condition_func(output)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"When choosing next node after {node}:\\n\"\n",
    "                f\"Condition function {condition_func}({output}) returned \\n{type(e).__name__}:'{e}'\"\n",
    "                ).with_traceback(e.__traceback__)\n",
    "\n",
    "        # if any condition function returned something other than a boolean, raise an error\n",
    "        if not isinstance(condition_result,bool):\n",
    "            raise ValueError(f\"When choosing next node after {node}:\\n\"\n",
    "                f\"Condition function {condition_func} returned {condition_result} which is not a boolean when evaluated on output {output}\")\n",
    "        condition_results[target] = condition_result\n",
    "\n",
    "    logger.debug(f\"Condition results for node '{node}' with output {output}: {condition_results}\")\n",
    "    # if there are more than 2 trues\n",
    "        # raise an error\n",
    "    num_trues = sum(condition_results.values())\n",
    "    if num_trues > 1:\n",
    "        raise ValueError(f\"When choosing next node after {node}:\\n\"\n",
    "            f\"More than one condition function succeeded when evaluated on output {output}\"\n",
    "            f\"condition results: {condition_results}\"\n",
    "            )\n",
    "    # if there is one true, return the target node of that condition\n",
    "    elif num_trues == 1:\n",
    "        chosen_target = next(target for target,result in condition_results.items() if result)\n",
    "    # if there are no trues, return the default target\n",
    "    else:\n",
    "        chosen_target = default_target\n",
    "    \n",
    "    return chosen_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Run Flow Diagrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from stringdale.core import (\n",
    "    new_combinations,\n",
    "    merge_list_dicts,\n",
    "    dict_cartesian_product\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "flow_logger = logging.getLogger(f'{__name__}.flow')\n",
    "\n",
    "\n",
    "async def _wait_for_tasks( tasks):\n",
    "    \"\"\"Wait for any task to complete from any of the task dictionaries\"\"\"\n",
    "    all_tasks = (*tasks['regular'],*tasks['iterator'],*tasks['subdiagram'])\n",
    "    if not all_tasks:\n",
    "        return None\n",
    "    done, _ = await asyncio.wait(\n",
    "        all_tasks,\n",
    "        return_when=asyncio.FIRST_COMPLETED\n",
    "    )\n",
    "    return done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _has_foreach(graph,node):\n",
    "    return graph.nodes[node].get('for_each',list()) != []\n",
    "\n",
    "class NodeState(enum.Enum):\n",
    "    waiting = 0\n",
    "    running = 1\n",
    "    finished = 2\n",
    "\n",
    "@patch\n",
    "def _did_all_fathers_run(self:Diagram,graph,node):\n",
    "    fathers = list(graph.predecessors(node))\n",
    "    flow_logger.debug(f\"Checking if all fathers {fathers} for node '{node}' have run at least once. node state: {self.node_state}\")\n",
    "    return all(self.node_state[father] != NodeState.waiting for father in fathers)\n",
    "\n",
    "@patch\n",
    "def _did_all_fathers_finish(self:Diagram,graph,node):\n",
    "    fathers = list(graph.predecessors(node))\n",
    "    flow_logger.debug(f\"Checking if all fathers {fathers} for node '{node}' have finished. node state: {self.node_state}\")\n",
    "    return all(self.node_state[father] == NodeState.finished for father in fathers)\n",
    "\n",
    "@patch\n",
    "def _running_node_tasks(self:Diagram,node):\n",
    "    graph = self.graph\n",
    "    task_nodes = set()\n",
    "    for tasks_per_type in self.tasks.values():\n",
    "        for task in tasks_per_type.values():\n",
    "            task_nodes.add(task[0])\n",
    "    return task_nodes\n",
    "\n",
    "\n",
    "@patch\n",
    "def can_generate_new_input(self:Diagram,graph,node):\n",
    "    flow_logger.debug(f\"Checking if we can generate new input for node '{node}'. node state: {self.node_state}\")\n",
    "    if _has_foreach(graph,node):\n",
    "        flow_logger.debug(f\"Node '{node}' has foreach, checking if all fathers have run at least once\")\n",
    "        res =  self._did_all_fathers_run(graph,node)\n",
    "    else:\n",
    "        flow_logger.debug(f\"Node '{node}' does not have foreach, checking if all fathers have finished\")\n",
    "        res = self._did_all_fathers_finish(graph,node)\n",
    "\n",
    "    flow_logger.debug(f\"Node '{node}' can generate new input: {res}\")\n",
    "    return res\n",
    "\n",
    "@patch\n",
    "def update_state(self:Diagram,graph,node):\n",
    "    if self._did_all_fathers_finish(graph,node) and node not in self._running_node_tasks(graph):\n",
    "        new_state = NodeState.finished\n",
    "    else:\n",
    "        new_state = NodeState.running\n",
    "    flow_logger.debug(f\"Updating state for node '{node}'. new state: {new_state}\")\n",
    "    self.node_state[node] = new_state\n",
    "\n",
    "\n",
    "    # self is running is any of its fathers are still running and it is not a foreach node\n",
    "    # self is finished if all fathers are finished and it is not a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def enqueue_task(self:Diagram, node, input_, idx):\n",
    "    \"\"\"\n",
    "    Create appropriate task type and add to corresponding task dict.\n",
    "    Handles AsyncIter initialization and tracks task creation time.\n",
    "    \n",
    "    Args:\n",
    "        node: Node to execute\n",
    "        input_: Input data for the node\n",
    "        idx: Execution index for the node\n",
    "        tasks: Dict of regular tasks\n",
    "        iterator_tasks: Dict of iterator tasks\n",
    "        subdiagram_tasks: Dict of subdiagram tasks\n",
    "    \"\"\"\n",
    "    tasks = self.tasks\n",
    "    func = self[node]\n",
    "    creation_time = datetime.now()\n",
    "    \n",
    "    if isinstance(func, Diagram):\n",
    "        # Create subdiagram task\n",
    "        # copy the subdiagram so that we dont share state between them if they are used multiple times or in foreach\n",
    "        subdiagram = copy(func)\n",
    "        subdiagram_iter = self.run_subdiagram_iter(node, input_,subdiagram,idx)\n",
    "        task = asyncio.create_task(subdiagram_iter.__anext__())\n",
    "        task_info = (node, idx, subdiagram, subdiagram_iter, input_, creation_time)\n",
    "        tasks['subdiagram'][task] = task_info\n",
    "        \n",
    "\n",
    "    else:\n",
    "        # Create regular task\n",
    "        task = asyncio.create_task(self.run_node(node, input_,idx))\n",
    "        task_info = (node, idx, func, None ,input_, creation_time)\n",
    "        tasks['regular'][task] = task_info\n",
    "\n",
    "    if isinstance(input_,dict):\n",
    "        pretty_input_ = input_\n",
    "    elif isinstance(input_,FunctionInput):\n",
    "        pretty_input_ = input_.to_positional_kwargs()\n",
    "    else:\n",
    "        pretty_input_ = input_\n",
    "    input_str = ', '.join([f\"{k}={v}\" for k,v in pretty_input_.items()])\n",
    "    flow_logger.debug(f\"Enqueued {task.get_name()} for {node}[{idx}]({input_str})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _pretty_tasks(tasks):\n",
    "    pretty_tasks = {}\n",
    "    for task_type in tasks:\n",
    "        pretty_tasks[task_type] = {task.get_name():f'{node}[{idx}]({input_})' for task,(node,idx,_,input_,_) in tasks[task_type].items()}\n",
    "    return pretty_tasks\n",
    "\n",
    "@patch\n",
    "def handle_finished_task(self:Diagram, task):\n",
    "    \"\"\"Handle a completed task and return node, trace, and outputs\n",
    "    \n",
    "    Args:\n",
    "        task: The completed asyncio task\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of:\n",
    "        - node: The node that completed\n",
    "        - trace: The execution trace (or None)\n",
    "        - outputs: List of outputs (or None)\n",
    "    \"\"\"\n",
    "    end_time = datetime.now()\n",
    "    trace = None\n",
    "    \n",
    "    tasks = self.tasks\n",
    "    regular_tasks = tasks['regular']\n",
    "    iterator_tasks = tasks['iterator']\n",
    "    subdiagram_tasks = tasks['subdiagram']\n",
    "\n",
    "    process_output = False\n",
    "\n",
    "    # Handle regular task\n",
    "    if task in regular_tasks:\n",
    "        node, idx, func, _ , input_, start_time = regular_tasks.pop(task)\n",
    "        input_,output = task.result()\n",
    "        process_output = True\n",
    "\n",
    "        trace = self.prep_trace(node, input_=input_, output=output, \n",
    "                              type=DiagramType.flow, idx=idx,\n",
    "                              start_time=start_time, end_time=end_time)\n",
    "\n",
    "        self.update_state(self.factored_graph,node)\n",
    "            \n",
    "    # Handle subdiagram task\n",
    "    elif task in subdiagram_tasks:\n",
    "        node, idx, subdiagram, subdiagram_iter, input_, start_time = subdiagram_tasks.pop(task)\n",
    "        try:\n",
    "            trace = task.result() # Already a trace\n",
    "            # Queue up next subdiagram trace\n",
    "            next_task = asyncio.create_task(subdiagram_iter.__anext__())\n",
    "            subdiagram_tasks[next_task] = (node, idx,subdiagram, subdiagram_iter, \n",
    "                                         input_, datetime.now())\n",
    "            \n",
    "        except StopAsyncIteration:\n",
    "            # Subdiagram complete - prep final trace and get output\n",
    "            output = subdiagram.output\n",
    "            process_output = True\n",
    "            \n",
    "            if not subdiagram.anon:\n",
    "                trace = self.prep_trace(node, input_=input_, output=output,\n",
    "                                  type=DiagramType.flow, idx=idx,\n",
    "                                  start_time=start_time, end_time=end_time)\n",
    "\n",
    "        \n",
    "            self.update_state(self.factored_graph,node)\n",
    "                \n",
    "    # Apply node output transformations\n",
    "\n",
    "    if process_output:\n",
    "        node_data = self.factored_graph.nodes[node]\n",
    "\n",
    "        for_each = node_data.get('for_each',None)\n",
    "        if for_each is not None:\n",
    "            output = [output]\n",
    "            if node_data.get('flat', False):\n",
    "                output = [item for output in output for item in output]\n",
    "            if node_data.get('filter', False):\n",
    "                output = [output for output in output if output]\n",
    "    else:\n",
    "        output = None\n",
    "    \n",
    "    return node, trace, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@wrap_exception(\"\"\"When trying to map previous outputs {{prev_outputs}}\n",
    "to inputs for node {{node}} with port mapping {{port_mapping}}\\n\n",
    "got partial input {{partial_input}}\n",
    "regular inputs {{regular_inputs}}\n",
    "unused stream inputs {{unused_stream_inputs}}\n",
    "\"\"\")\n",
    "def _map_to_inputs(node,prev_outputs,port_mapping,is_father_stream,for_each_keys,regular_inputs,unused_stream_inputs):\n",
    "\n",
    "    \n",
    "\n",
    "    flow_logger.debug(f\"Mapping previous outputs to inputs for node '{node}':\\n\"\n",
    "        f\"prev_outputs: {prev_outputs}\\n\"\n",
    "        f\"port_mapping: {port_mapping}\\n\"\n",
    "        f\"for_each_keys: {for_each_keys}\"\n",
    "        )\n",
    "\n",
    "    if is_father_stream:\n",
    "        list_keys = list(prev_outputs.keys())\n",
    "    else:\n",
    "        list_keys = []\n",
    "    partial_input = multi_map(prev_outputs,port_mapping,as_list_keys=list_keys)\n",
    "\n",
    "    for key,value in partial_input.items():\n",
    "        if key in for_each_keys:\n",
    "            assign_to = unused_stream_inputs\n",
    "        else:\n",
    "            assign_to = regular_inputs\n",
    "        if is_father_stream:\n",
    "            if not key in assign_to:\n",
    "                assign_to[key] = []\n",
    "            assign_to[key].extend(value)\n",
    "        else:\n",
    "            assign_to[key] = value\n",
    "    flow_logger.debug(f\"\\n\"\n",
    "            f\"partial_input: {partial_input}\\n\"\n",
    "            f\"regular_inputs: {regular_inputs}\\n\"\n",
    "            f\"unused_stream_inputs: {unused_stream_inputs}\\n\"\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "@patch\n",
    "def enqueue_new_input(self:Diagram,graph,node,father_node,new_father_outputs):\n",
    "\n",
    "    \"\"\"\n",
    "    Lets look at this example\n",
    "    U.(x,y)->V.(a,b)  V foreach a  U is a stream node\n",
    "    W.(z,w)->V.(c,d)  V foreach d  W is a regular node\n",
    "    M.(a,b)->V.(e,f)  V for each e,f, M is a stream node\n",
    "    N.(a,b)->V.(g,h)  V for each g,h, N is a regular node\n",
    "\n",
    "    We need to have all 8 of a,b,c,d,e,f,g,h\n",
    "    Since W is regular, once we compute it, we portmap it to c,d and overide them\n",
    "    Since U is a stream node, we need to get every item from it and extend the port mappings\n",
    "    Both W and U have a regular port, so we need to wait for both to finish\n",
    "    N is a regular node but all it's outputs are foreach nodes, \n",
    "        so we dont need to wait for it but we cant run until it finishes\n",
    "\n",
    "    M only has foreach nodes, so we dont need to wait for it\n",
    "    We need to wait till for both ot finish since both have a foreach \n",
    "\n",
    "\n",
    "    then we have a mapped dict of:\n",
    "    {\n",
    "     a: a list since U is a stream node\n",
    "     b: a list since U is a stream node\n",
    "     c: some object since W is a regular node\n",
    "     d: a list since we need to for each it (we need to check this)\n",
    "     e-h: lists since we are foreach\n",
    "    }\n",
    "    \"\"\"\n",
    "    inputs_per_node = self.inputs_per_node\n",
    "    is_father_stream = _has_foreach(graph,father_node)\n",
    "    used_stream_inputs = inputs_per_node[node]['stream_used']\n",
    "    unused_stream_inputs = inputs_per_node[node]['stream_unused']\n",
    "    regular_inputs = inputs_per_node[node]['regular']\n",
    "    \n",
    "    graph = self.factored_graph\n",
    "    port_mapping = graph.nodes[node]['mapping']\n",
    "    for_each_keys = graph.nodes[node].get('for_each',list())\n",
    "\n",
    "    flow_logger.debug(f\"Trying to enqueue new input for node '{node}' with father node '{father_node}' and new father outputs {new_father_outputs}\")\n",
    "\n",
    "    # map the new father outputs to inputs\n",
    "    _map_to_inputs(node,new_father_outputs,port_mapping,is_father_stream,for_each_keys,regular_inputs,unused_stream_inputs)\n",
    "\n",
    "    if not self.can_generate_new_input(graph,node):\n",
    "        flow_logger.debug(f\"Not all father nodes have finished for node '{node}', skipping enqueueing new input\")\n",
    "        return\n",
    "\n",
    "    # load state first time we need it\n",
    "    state_keys = self._get_state_input_keys(node)\n",
    "    state_target_ports = list(set(itertools.chain(\n",
    "        *[list(v.keys()) for k,v in graph.nodes[node].get('read_state',{}).items()]\n",
    "        )))\n",
    "    if len(state_keys) == 0:\n",
    "        need_to_load_state = False\n",
    "    else:\n",
    "        need_to_load_state = False\n",
    "        for state_target_port in state_target_ports:\n",
    "            if state_target_port not in regular_inputs and state_target_port not in used_stream_inputs:\n",
    "                need_to_load_state = True\n",
    "                break\n",
    "\n",
    "    \n",
    "    if need_to_load_state:\n",
    "        flow_logger.debug(f\"Need to load state keys {state_keys} for node '{node}', mapping state\")\n",
    "        state_values = self._get_state_input(node)\n",
    "        _map_to_inputs(node,state_values,port_mapping,False,for_each_keys,regular_inputs,unused_stream_inputs)\n",
    "\n",
    "\n",
    "    # merge foreach inputs to generate new tasks\n",
    "    new_input_batches = []\n",
    "    flow_logger.debug(f\"Merging input streams to generate new tasks for node '{node}':\\n\"\n",
    "                f\"used_stream_inputs: {used_stream_inputs}\\n\"\n",
    "                f\"unused_stream_inputs: {unused_stream_inputs}\\n\"\n",
    "                f\"regular_inputs: {regular_inputs}\\n\"\n",
    "                )\n",
    "\n",
    "    if len(unused_stream_inputs) > 0:\n",
    "        for merged_stream_input in new_combinations(unused_stream_inputs,used_stream_inputs):\n",
    "            input_ = merged_stream_input|regular_inputs\n",
    "            new_input_batches.append(input_)\n",
    "    else:\n",
    "        new_input_batches = [regular_inputs]\n",
    "\n",
    "    flow_logger.debug(f\"new_input_batches: {new_input_batches}, splitting by foreach keys: {for_each_keys}\")\n",
    "    if len(for_each_keys) > 0:\n",
    "        new_inputs = []\n",
    "        for batch in new_input_batches:\n",
    "            try:\n",
    "                new_inputs.extend(dict_cartesian_product(batch,for_each_keys))\n",
    "            except KeyError as e:\n",
    "                raise e\n",
    "    else:\n",
    "        new_inputs = new_input_batches\n",
    "\n",
    "    new_inputs = [dict(input_) for input_ in new_inputs]\n",
    "    # enqueue the new inputs to task\n",
    "    # if len(new_inputs) == 0:\n",
    "    #     raise AssertionError(f'No new inputs were generated even though all father nodes have finished for {node}')\n",
    "\n",
    "    flow_logger.debug(f\"Enqueuing {len(new_inputs)} new inputs for node '{node}':\\n\"\n",
    "                f\"new_inputs: {new_inputs}\\n\")\n",
    "    for input_ in new_inputs:\n",
    "        self.enqueue_task(node,input_,idx=self._get_next_index(node,self.counters))\n",
    "\n",
    "    # now we move all the unused stream inputs to the used stream inputs\n",
    "    for key in unused_stream_inputs:\n",
    "        if not key in used_stream_inputs:\n",
    "            used_stream_inputs[key] = []\n",
    "        used_stream_inputs[key].extend(unused_stream_inputs[key])\n",
    "        unused_stream_inputs[key] = []\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def _get_next_index(self:Diagram,node,counters):\n",
    "    if _has_foreach(self.factored_graph,node):\n",
    "        return next(counters[node])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "@patch\n",
    "async def arun_flow(self:Diagram, input_, state=None):\n",
    "    \"\"\"Run a flow diagram asynchronously, yielding traces for each node execution\"\"\"\n",
    "    graph = self.graph\n",
    "    self.counters = {node: itertools.count() for node in graph.nodes}\n",
    "    \n",
    "    # Track three types of tasks\n",
    "    tasks = {\n",
    "        'regular':{},\n",
    "        'iterator':{},\n",
    "        'subdiagram':{}\n",
    "    }\n",
    "    self.tasks = tasks\n",
    "    \n",
    "    inputs_per_node = {}\n",
    "    for node in graph.nodes:\n",
    "        inputs_per_node[node] = {\n",
    "            'regular':{},\n",
    "            'stream_used':{},\n",
    "            'stream_unused':{},\n",
    "            }\n",
    "\n",
    "    self.inputs_per_node = inputs_per_node\n",
    "\n",
    "    self.node_state = {node:NodeState.waiting for node in graph.nodes}\n",
    "\n",
    "    flow_logger.debug(f\"Running flow diagram {self.name} with input {input_}\")\n",
    "    # enqueue the start node\n",
    "    # Start with initial task\n",
    "    \n",
    "    # TODO add support for progress bars\n",
    "    # after wait for task, update the progress bar based on node\n",
    "    # in enqueue_new_input, update the progress bar total based on the number of new inputs and reset \n",
    "    input_ = self.compute_node_input(self.start_node,input_,state,raw_input=True)\n",
    "\n",
    "    self.enqueue_task(self.start_node,input_, idx=self._get_next_index(self.start_node,self.counters))\n",
    "    \n",
    "    # Main processing loop\n",
    "    while tasks or iterator_tasks or subdiagram_tasks:\n",
    "        done_tasks = await _wait_for_tasks(tasks)\n",
    "        \n",
    "        if not done_tasks:\n",
    "            break\n",
    "        \n",
    "        flow_logger.debug(f\"Done tasks: {[task.get_name() for task in done_tasks]}\")\n",
    "        for task in done_tasks:\n",
    "            node,trace,outputs = self.handle_finished_task(task)\n",
    "            if trace is not None:\n",
    "                yield trace\n",
    "            if outputs is not None:\n",
    "                for successor in graph.successors(node):\n",
    "                    logger.debug(f\"Enqueuing new input for successor {successor} of node {node}\")\n",
    "                    self.enqueue_new_input(graph,successor,node,{node:outputs})\n",
    "            if node == self.end_node:\n",
    "                self.finished = True\n",
    "                self.output = outputs\n",
    "                break\n",
    "\n",
    "    self.node_state = None\n",
    "    self.tasks = None\n",
    "    self.inputs_per_node = None\n",
    "    flow_logger.debug(f\"Flow diagram {self.name} finished with output {self.output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main execution functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@wrap_exception(\"\"\"Error when loading state {{outside_state}} with current state {{current_state}}\"\"\")\n",
    "@patch\n",
    "def load_external_state(self:Diagram,outside_state=None):\n",
    "    # TODO maybe simply override all keys of the current state with the outside state\n",
    "    current_state = self.state\n",
    "    if outside_state is None:\n",
    "        if current_state is None:\n",
    "            return self.state_class()\n",
    "        else:\n",
    "            return current_state\n",
    "\n",
    "    if isinstance(outside_state,BaseModel):\n",
    "        outside_state_dict = outside_state.model_dump()\n",
    "    else:\n",
    "        outside_state_dict = outside_state\n",
    "\n",
    "    if current_state is None:\n",
    "        current_state_dict = {}\n",
    "    else:\n",
    "        current_state_dict = current_state.model_dump()\n",
    "\n",
    "    new_state = self.state_class(**(outside_state_dict| current_state_dict))\n",
    "    \n",
    "    return new_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "async def arun(self:Diagram, input:Any ,state:Union[BaseModel,Dict]=None,progress_bars:bool=True,trace_nested:bool=True):\n",
    "    \"\"\"\n",
    "    Asynchronously run the diagram with the given input and state.\n",
    "\n",
    "    Args:\n",
    "        input: The input data to process through the diagram\n",
    "        state: Optional state to initialize the diagram with\n",
    "        progress_bars: Whether to display progress bars during execution (default True). Deprecated.\n",
    "        trace_nested: Whether to trace nested diagram execution (default True)\n",
    "\n",
    "    Yields:\n",
    "        Trace objects containing execution state at each step\n",
    "    \"\"\"\n",
    "    \n",
    "    if self.finished in [True,None]:   \n",
    "        # meaning we have to run the diagram from scratch\n",
    "        self.reset()\n",
    "\n",
    "    self.state = self.load_external_state(state)\n",
    "\n",
    "    self.trace_nested = trace_nested\n",
    "\n",
    "    self.progress_bars = progress_bars\n",
    "    self.input = input\n",
    "\n",
    "    try:\n",
    "        if self.type == DiagramType.decision:\n",
    "            async for trace in self.arun_decision(input,state):\n",
    "                yield trace\n",
    "        elif self.type == DiagramType.flow:\n",
    "            async for trace in self.arun_flow(input,state):\n",
    "                yield trace\n",
    "        else:\n",
    "            raise ValueError(f\"Diagram type {self.type} is not supported\")\n",
    "    except Exception as e:\n",
    "        raise e from None    \n",
    "\n",
    "@patch\n",
    "def run(self:Diagram, input:Any ,state:Union[BaseModel,Dict]=None,progress_bars:bool=True,trace_nested:bool=True):\n",
    "    \"\"\"\n",
    "    Run the diagram with the given input and state.\n",
    "\n",
    "    Args:\n",
    "        input: The input data to process through the diagram\n",
    "        state: Optional state to initialize the diagram with\n",
    "        progress_bars: Whether to display progress bars during execution (default True). Deprecated.\n",
    "        trace_nested: Whether to trace nested diagram execution (default True)\n",
    "\n",
    "    Yields:\n",
    "        Trace objects containing execution state at each step\n",
    "    \"\"\"\n",
    "    async_gen = self.arun(input,state,progress_bars,trace_nested)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.set_task_factory(asyncio.eager_task_factory)\n",
    "    try:\n",
    "        while True:\n",
    "            yield loop.run_until_complete(async_gen.__anext__())\n",
    "    except StopAsyncIteration:\n",
    "        logger.debug('StopAsyncIteration recieved, ending run')\n",
    "    except Exception as e:\n",
    "        raise e from None\n",
    "\n",
    "@patch\n",
    "def run_all(self:Diagram, input:Any ,state:Union[BaseModel,Dict]=None,progress_bars:bool=True,trace_nested:bool=True):\n",
    "    \"\"\"\n",
    "    Run the diagram to completion and return the final output.\n",
    "\n",
    "    Args:\n",
    "        input: The input data to process through the diagram\n",
    "        state: Optional state to initialize the diagram with\n",
    "        progress_bars: Whether to display progress bars during execution (default True). Deprecated.\n",
    "        trace_nested: Whether to trace nested diagram execution (default True)\n",
    "\n",
    "    Returns:\n",
    "        The final output after diagram execution completes\n",
    "    \"\"\"\n",
    "    for trace in self.run(input,state,progress_bars,trace_nested):\n",
    "        pass\n",
    "    return self.output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO future\n",
    "# TODO add support for progress bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
